# AI/ML Module Environment Variables
# Copy this file to .env and fill in your values

# ========================================
# FIREBASE CONFIGURATION
# ========================================
FIREBASE_CREDENTIALS_PATH=./firebase-credentials.json
FIREBASE_PROJECT_ID=smartcitysense
FIRESTORE_COLLECTION_EVENTS=events
FIRESTORE_COLLECTION_PREDICTIONS=predictions
FIRESTORE_COLLECTION_ALERTS=alerts

# ========================================
# MODEL CONFIGURATION
# ========================================
# Vision Models
YOLO_MODEL_PATH=./models/yolov8n.pt
YOLO_MODEL_SIZE=n  # n, s, m, l, x (nano to xlarge)
VISION_CONFIDENCE_THRESHOLD=0.65
VISION_IOU_THRESHOLD=0.45
MAX_IMAGE_SIZE=1280
MAX_VIDEO_DURATION_SECONDS=30
MAX_VIDEO_FRAMES=60

# Predictive Models
ANOMALY_MODEL_PATH=./models/isolation_forest.pkl
PROPHET_MODEL_PATH=./models/prophet_model.pkl
ANOMALY_CONTAMINATION=0.1  # Expected % of anomalies
ANOMALY_N_ESTIMATORS=100
FORECAST_PERIODS=24  # Hours to forecast ahead
ANOMALY_THRESHOLD=0.85  # Score threshold for alerts

# Text Processing Models (Member B1)
SUMMARIZATION_LLM_PROVIDER=gemini  # gemini or openai
SUMMARIZATION_MODEL_NAME=gemini-1.5-flash
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
MAX_REPORTS_PER_SUMMARY=50
SUMMARY_MAX_LENGTH=200
SENTIMENT_MODEL_NAME=distilbert-base-uncased-finetuned-sst-2-english
ENABLE_MULTILINGUAL=False
TEXT_BATCH_SIZE=32
FIRESTORE_COLLECTION_SUMMARIZED_EVENTS=summarized_events
FIRESTORE_COLLECTION_MOOD_MAP=mood_map

# ========================================
# API CONFIGURATION
# ========================================
API_HOST=0.0.0.0
API_PORT=8001
API_WORKERS=4
API_RELOAD=True  # Set False in production
API_LOG_LEVEL=info
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ========================================
# PROCESSING LIMITS
# ========================================
MAX_UPLOAD_SIZE_MB=10
BATCH_SIZE=32
PREDICTION_WINDOW_MINUTES=15
MIN_REPORTS_FOR_ANOMALY=5
ALERT_COOLDOWN_MINUTES=30

# ========================================
# LOGGING
# ========================================
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR
LOG_FILE=./logs/ai_ml.log
LOG_ROTATION=10 MB
LOG_RETENTION=30 days

# ========================================
# CACHE & PERFORMANCE
# ========================================
ENABLE_MODEL_CACHE=True
CACHE_TTL_SECONDS=3600
USE_GPU=True  # Auto-detect CUDA availability

# ========================================
# INTEGRATION ENDPOINTS
# ========================================
BACKEND_API_URL=http://localhost:8000
BACKEND_API_KEY=your_backend_api_key_here

# ========================================
# DEVELOPMENT/TESTING
# ========================================
ENVIRONMENT=development  # development, staging, production
MOCK_MODE=False
SAVE_DEBUG_IMAGES=True
TEST_DATA_PATH=./tests/data
